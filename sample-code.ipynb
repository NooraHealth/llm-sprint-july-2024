{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b40d5e54-4741-4459-a605-c4eb69a548ac",
   "metadata": {},
   "source": [
    "# Sample code for generating dummy data for monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457f203a-a109-482b-a5f6-5e08ccabeb1c",
   "metadata": {},
   "source": [
    "## Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e136f766-78f5-42cd-b901-48e752e2ad0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install langfuse pandas weaviate-client jupyter openai ragas  # or\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de6f517-7b1e-47b5-9d81-d30e0083021a",
   "metadata": {},
   "source": [
    "## Setup env vars\n",
    "\n",
    "1. Create a weaviate cluster at https://console.weaviate.cloud/create-cluster \\\n",
    "   [**Note**: ingested data in free account expires after 14 days]\n",
    "2. *Wait* until the cluster is created\n",
    "3. Click on the ![Weaviate code button](weaviate-connect.svg) button to show code to connect to the cluster\n",
    "4. Add the REST endpoint into `WCS_URL` environment variable \\\n",
    "   `export WCS_URL=\"https://url.here\"`\n",
    "5. Also set the `WCS_API_KEY` environment variable to the admin API key. Click on the **API keys** button to reveal it. \\\n",
    "   `export WCS_API_KEY=\"api-key-here\"`\n",
    "6. Create new OpenAI API key at https://platform.openai.com/api-keys \\\n",
    "   `export OPENAI_API_KEY=\"key-here\"`\n",
    "7. Create new Langfuse API keys at https://cloud.langfuse.com/ (First create a project) \\\n",
    "   `export LANGFUSE_SECRET_KEY=\"secret-key\"` \\\n",
    "   `export LANGFUSE_PUBLIC_KEY=\"public-key\"` \\\n",
    "   `export LANGFUSE_HOST=\"https://cloud.langfuse.com\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6a4e60-b7b1-4f50-a7b4-f2c0b4d2e759",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e8b275-4399-4569-819f-82f1ec3dd077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# builtin packages\n",
    "import os\n",
    "import json\n",
    "from textwrap import dedent\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# 3rd party packages\n",
    "import weaviate\n",
    "import pandas as pd\n",
    "from langfuse.openai import OpenAI\n",
    "from langfuse import Langfuse\n",
    "from langfuse.decorators import observe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ab14f5-0758-4ddb-959d-3807752cf96f",
   "metadata": {},
   "source": [
    "## Connect to weaviate cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629b22dc-a6ad-4bfd-9e7e-52d8d02a69ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set these environment variables\n",
    "URL = os.getenv(\"WCS_URL\")\n",
    "APIKEY = os.getenv(\"WCS_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Connect to a WCS instance\n",
    "wclient = weaviate.connect_to_wcs(\n",
    "    cluster_url=URL,\n",
    "    auth_credentials=weaviate.auth.AuthApiKey(APIKEY),\n",
    "    headers = {\n",
    "        \"X-OpenAI-Api-Key\": OPENAI_API_KEY,\n",
    "    }\n",
    ")\n",
    "lf_client = Langfuse()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6006e0-8a35-41d7-9e33-409b188cc214",
   "metadata": {},
   "source": [
    "## Terms\n",
    "1. **Collection** \\\n",
    "   A collection is like a table\n",
    "2. **Field** in a collection \\\n",
    "   A field is like a column of a table\n",
    "3. **Vector** \\\n",
    "   A vector is an sequence of numbers. [Ref: ChatGPT]\n",
    "4. **Embedding** \\\n",
    "   An embedding is the mapping of an object to a vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5f1a0b-08f2-4df0-b430-e62e0633d40e",
   "metadata": {},
   "source": [
    "## Generating vector embeddings\n",
    "\n",
    "The following things will happen when you run the code given below:\n",
    "1. Read the `rag.csv` and do a basic cleanup\n",
    "2. Create the collection with the specified schema and OpenAI's `text-embedding-3-large` embedding model. Click [here](https://platform.openai.com/docs/guides/embeddings) for more info on other OpenAI's models.\n",
    "3. Import the records from the CSV to the newly created collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5504300f-2719-479a-a816-773806fae0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_collection(collection_name: str, *, recreate: bool) -> weaviate.collections.collection.Collection:\n",
    "    if recreate:\n",
    "        wclient.collections.delete(collection_name)\n",
    "\n",
    "    try:\n",
    "        wclient.collections.list_all()[collection_name]\n",
    "    except KeyError:\n",
    "        pass\n",
    "    else:\n",
    "        return wclient.collections.get(collection_name)\n",
    "\n",
    "    df = pd \\\n",
    "        .read_csv('rag.csv', dtype=str) \\\n",
    "        .dropna(ignore_index=True) \\\n",
    "        .drop_duplicates(subset=[\"question\"], ignore_index=True) \\\n",
    "        .map(str.strip)\n",
    "    \n",
    "    collection = wclient.collections.create(\n",
    "        name=collection_name,\n",
    "        vectorizer_config=weaviate.classes.config.Configure.Vectorizer.text2vec_openai(model=\"text-embedding-3-large\"),\n",
    "        properties=[\n",
    "            # Define db schema here\n",
    "            weaviate.classes.config.Property(name=\"question\", data_type=weaviate.classes.config.DataType.TEXT),\n",
    "            weaviate.classes.config.Property(name=\"answer\", data_type=weaviate.classes.config.DataType.TEXT),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Import the records from the CSV to our weaviate collection\n",
    "    with collection.batch.rate_limit(requests_per_minute=100) as batch:\n",
    "        for _, row in df.iterrows():\n",
    "            batch.add_object(properties=row.to_dict())\n",
    "\n",
    "    return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b85f6f-493f-44f7-ac25-5b3bc677431f",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = get_or_create_collection(\"Medqna\", recreate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc3302c-ae8c-42ae-bbbf-2d6131c5ebe5",
   "metadata": {},
   "source": [
    "## Get top 3 matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0effcb-cddc-4dec-8893-beca3b8bc5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_3_matches(message, trace=None):\n",
    "    _start = datetime.now(timezone.utc)\n",
    "    results = collection \\\n",
    "        .query \\\n",
    "        .near_text(message, limit=3) \\\n",
    "        .objects\n",
    "    results_new = [x.properties for x in results]\n",
    "    context = \"\\n\".join(\n",
    "        f'Question: \"{x['question']}\" , Answer: \"\"\"{x['answer']}\"\"\"\\n\\n'\n",
    "        for x in results_new\n",
    "    )\n",
    "    _end = datetime.now(timezone.utc)\n",
    "    if trace is not None:\n",
    "        trace.generation(\n",
    "            name = \"weaviate-near-text\",\n",
    "            input=message,\n",
    "            output=context,\n",
    "            metadata={\"top_results\": [*results_new], \"collection_name\": collection.name, \"limit\": 3},\n",
    "            start_time=_start,\n",
    "            end_time=_end,\n",
    "        )\n",
    "    return context, results_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34640e2d-b15d-4034-a9b0-5eb531b73f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"What food to avoid during pregnancy ?.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d592ac-361b-4abb-a8ad-47a9734d9299",
   "metadata": {},
   "outputs": [],
   "source": [
    "context, _ = get_top_3_matches(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23cb345-41dd-4c2e-b157-a5fa5778109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = lf_client.get_prompt(\"medical-doctor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53cb0c6-7fd0-47aa-ad94-6bba91e0d59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = OpenAI()\n",
    "\n",
    "response = openai_client.chat.completions.create(\n",
    "    # model=\"gpt-4-turbo-preview\",\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": prompt.compile(context=context)},\n",
    "        {\"role\": \"user\"  , \"content\": message},\n",
    "    ],\n",
    "    temperature=0.2,\n",
    "    max_tokens=256,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a1e1b7-7315-44cd-bb11-a510f1168885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import metrics\n",
    "from ragas.metrics import faithfulness, answer_relevancy, context_precision\n",
    "from ragas.metrics.critique import harmfulness\n",
    " \n",
    "# metrics you chose\n",
    "metrics = [faithfulness, answer_relevancy, harmfulness]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af985e86-5b2b-4f63-a325-a80025924170",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.run_config import RunConfig\n",
    "from ragas.metrics.base import MetricWithLLM, MetricWithEmbeddings\n",
    " \n",
    " \n",
    "# util function to init Ragas Metrics\n",
    "def init_ragas_metrics(metrics, llm, embedding):\n",
    "    for metric in metrics:\n",
    "        if isinstance(metric, MetricWithLLM):\n",
    "            metric.llm = llm\n",
    "        if isinstance(metric, MetricWithEmbeddings):\n",
    "            metric.embeddings = embedding\n",
    "        run_config = RunConfig()\n",
    "        metric.init(run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985655fa-f020-4d34-b9f8-e6fab59f3129",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    " \n",
    "# wrappers\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    " \n",
    "llm = ChatOpenAI()\n",
    "emb = OpenAIEmbeddings()\n",
    " \n",
    "init_ragas_metrics(\n",
    "    metrics,\n",
    "    llm=LangchainLLMWrapper(llm),\n",
    "    embedding=LangchainEmbeddingsWrapper(emb),\n",
    ")\n",
    "@observe()\n",
    "async def score_with_ragas(query, chunks, answer):\n",
    "    scores = {}\n",
    "    for m in metrics:\n",
    "        print(f\"calculating {m.name}\")\n",
    "        scores[m.name] = await m.ascore(\n",
    "            row={\"question\": query, \"contexts\": chunks, \"answer\": answer}\n",
    "        )\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a676015d-72cb-4fce-8f4d-26c0ea4b1cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@observe()\n",
    "def get_summarized_answer(message, trace):\n",
    "    context, _ = get_top_3_matches(message, trace)\n",
    "\n",
    "    openai_client = OpenAI()\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        # model=\"gpt-4-turbo-preview\",\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": prompt.compile(context=context)},\n",
    "            {\"role\": \"user\"  , \"content\": message},\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        max_tokens=256,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        trace_id=trace.id,\n",
    "    )\n",
    "    output = response.choices[0].message.content\n",
    "\n",
    "    # Update the trace with the output\n",
    "    trace.update(output=output)\n",
    "\n",
    "    return output, context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37faadaa-5361-4a58-ad02-40b41247571b",
   "metadata": {},
   "source": [
    "## Create a trace when you get a message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974c8cac-6ee0-4e8d-ae65-d061f412694a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = lf_client.trace(name = \"rag\", input=message, start_time=datetime.now(timezone.utc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ea2d6f-d6bf-401d-84ee-424be4b9468b",
   "metadata": {},
   "source": [
    "## Get output and context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f22b4c-67f7-4959-ae94-9555d8fa8d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "output, context = get_summarized_answer(message, trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48752b52-634c-476c-8ac9-473a2c20aad1",
   "metadata": {},
   "source": [
    "## Calculate the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995189e2-0d12-48f6-bfa9-701c51ef73a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ragas_scores = await score_with_ragas(message, [context], output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c536e1-677c-4fb6-b7f9-7a339bf225f2",
   "metadata": {},
   "source": [
    "## Send the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a8aa37-b029-4472-9a1e-b8e02ec86337",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in metrics:\n",
    "    trace.score(name=m.name, value=ragas_scores[m.name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979d71eb-be4d-4311-bfb8-d901b27c1078",
   "metadata": {},
   "source": [
    "## Mark the end of the trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70be739-852c-4a1e-bc3a-223d9a633e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace.update(end_time=datetime.now(timezone.utc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
